{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "c94b6b23",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "ba4bacd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(filename):\n",
    "    # Open and unzip the file of images:\n",
    "    fh = open(filename, 'rb')\n",
    "    # Read the header information into a bunch of variables\n",
    "    _ignored, n_images, columns, rows = struct.unpack('>IIII', fh.read(16))\n",
    "    # Read all the pixels into a NumPy array of bytes:\n",
    "    all_pixels = np.frombuffer(fh.read(), dtype=np.uint8)\n",
    "    # Reshape the pixels into a matrix where each line is an image:\n",
    "    return all_pixels.reshape(n_images, columns * rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "8b9274a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_ones(X):\n",
    "    c1 = np.ones(len(X))\n",
    "    return np.column_stack((c1, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "6169e6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(filename):\n",
    "    # Open and unzip the file of labels:\n",
    "    fj = open(filename, 'rb')\n",
    "    # Skip the header bytes:\n",
    "    fj.read(8)\n",
    "    # Read all the labels into a list:\n",
    "    all_labels = fj.read()\n",
    "    # Reshape the list of labels into a one-column matrix:\n",
    "    return np.frombuffer(all_labels, dtype=np.uint8).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "5670f9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(Y):\n",
    "    # Number of images:\n",
    "    numImages = len(Y)\n",
    "    # Number of classes:\n",
    "    numClasses = 10\n",
    "    # Initialize the encoded-Y matrix:\n",
    "    encode_Y = np.zeros((numImages, numClasses))\n",
    "    \n",
    "    for i in range(len(Y)):\n",
    "        digit = Y[i]\n",
    "        encode_Y[i][digit] = 1  \n",
    "    return encode_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "c95d5896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following commands load the data into\n",
    "# 60000 images, each 785 elements (1 bias + 28 * 28 pixels)\n",
    "X_train = stack_ones(load_images(\"train-images.idx3-ubyte\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "874ceefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60K labels, each with value 1 on index digit, and 0 otherwise\n",
    "Y_train = encode(load_labels(\"train-labels.idx1-ubyte\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "f2c9fbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10000 images, each 785 elements, with the same structure as X_train\n",
    "X_test = stack_ones(load_images(\"t10k-images.idx3-ubyte\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "c072ebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10000 labels, with the same encoding as Y_train\n",
    "Y_test = load_labels(\"t10k-labels.idx1-ubyte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "304e1aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "d00238aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigPredict(X, beta):\n",
    "    regresSum = np.matmul(X, beta)   \n",
    "    return sigmoid(regresSum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "32a447d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(X, beta):\n",
    "    Y_hat = sigPredict(X, beta)\n",
    "    L = np.argmax(Y_hat, axis = 1)\n",
    "    return L.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "9c3df570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(X, Y, beta):\n",
    "    Y_sig = sigPredict(X, beta)\n",
    "    Loss = ((-1)/len(X)) * np.sum((Y*np.log(Y_sig)) + ((1-Y)*np.log(1-Y_sig)))\n",
    "    return Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "4a63f223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X, Y, beta):\n",
    "    Y_hat = sigPredict(X, beta)\n",
    "    XT = np.transpose(X)\n",
    "    diff = Y_hat - Y\n",
    "    grad_beta = 1 / len(X) * np.dot(XT, diff)   \n",
    "    return grad_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "2c2f519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(numIter, X_train, Y_train, X_test, Y_test, beta):\n",
    "    L = classify(X_test, beta)\n",
    "    correct = np.sum(L == Y_test)\n",
    "    p = correct/len(X_test) * 100\n",
    "    Loss = loss(X_train, Y_train, beta)\n",
    "    print('When the iteration is', numIter, ', the percentage of correct classification is:', p, '% and the loss is', Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "656133e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(numIter, X_train, Y_train, X_test, Y_test, learningRate):\n",
    "    beta = np.zeros((len(X_train[0]), len(Y_train[0])))\n",
    "    for i in range(numIter):      \n",
    "        report(i, X_train, Y_train, X_test, Y_test, beta)\n",
    "        grad_beta = gradient(X_train, Y_train, beta)\n",
    "        beta -= grad_beta * learningRate\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "ff2b84ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When the iteration is 0 , the percentage of correct classification is: 9.8 % and the loss is 6.931471805599455\n",
      "When the iteration is 1 , the percentage of correct classification is: 68.04 % and the loss is 8.434456875083338\n",
      "When the iteration is 2 , the percentage of correct classification is: 68.10000000000001 % and the loss is 5.512047488923876\n",
      "When the iteration is 3 , the percentage of correct classification is: 68.62 % and the loss is 2.9568700735936546\n",
      "When the iteration is 4 , the percentage of correct classification is: 73.75 % and the loss is 1.8985387657057096\n",
      "When the iteration is 5 , the percentage of correct classification is: 81.99 % and the loss is 1.7558289155266746\n",
      "When the iteration is 6 , the percentage of correct classification is: 81.25 % and the loss is 1.674881272926218\n",
      "When the iteration is 7 , the percentage of correct classification is: 82.89 % and the loss is 1.623875243420281\n",
      "When the iteration is 8 , the percentage of correct classification is: 82.69 % and the loss is 1.5652805689746654\n",
      "When the iteration is 9 , the percentage of correct classification is: 83.61 % and the loss is 1.5292692651055577\n",
      "When the iteration is 10 , the percentage of correct classification is: 83.55 % and the loss is 1.4834968500183896\n",
      "When the iteration is 11 , the percentage of correct classification is: 84.3 % and the loss is 1.4547390723537277\n",
      "When the iteration is 12 , the percentage of correct classification is: 84.27 % and the loss is 1.4187844781439438\n",
      "When the iteration is 13 , the percentage of correct classification is: 84.84 % and the loss is 1.3942565669684222\n",
      "When the iteration is 14 , the percentage of correct classification is: 84.96000000000001 % and the loss is 1.3659350910622259\n",
      "When the iteration is 15 , the percentage of correct classification is: 85.34 % and the loss is 1.3445875188347647\n",
      "When the iteration is 16 , the percentage of correct classification is: 85.39999999999999 % and the loss is 1.3220198232096096\n",
      "When the iteration is 17 , the percentage of correct classification is: 85.81 % and the loss is 1.3034634184193592\n",
      "When the iteration is 18 , the percentage of correct classification is: 85.86 % and the loss is 1.285117113766232\n",
      "When the iteration is 19 , the percentage of correct classification is: 86.18 % and the loss is 1.2690683151500537\n",
      "When the iteration is 20 , the percentage of correct classification is: 86.22 % and the loss is 1.2537827753717958\n",
      "When the iteration is 21 , the percentage of correct classification is: 86.55000000000001 % and the loss is 1.2398963816638573\n",
      "When the iteration is 22 , the percentage of correct classification is: 86.50999999999999 % and the loss is 1.2268469039957433\n",
      "When the iteration is 23 , the percentage of correct classification is: 86.74 % and the loss is 1.214740575732478\n",
      "When the iteration is 24 , the percentage of correct classification is: 86.75 % and the loss is 1.2033678230704052\n",
      "When the iteration is 25 , the percentage of correct classification is: 86.87 % and the loss is 1.192694571096329\n",
      "When the iteration is 26 , the percentage of correct classification is: 86.92999999999999 % and the loss is 1.1826267784085118\n",
      "When the iteration is 27 , the percentage of correct classification is: 87.06 % and the loss is 1.1731133453159597\n",
      "When the iteration is 28 , the percentage of correct classification is: 87.1 % and the loss is 1.1640996430905364\n",
      "When the iteration is 29 , the percentage of correct classification is: 87.21 % and the loss is 1.1555433100032615\n",
      "When the iteration is 30 , the percentage of correct classification is: 87.29 % and the loss is 1.14740625825318\n",
      "When the iteration is 31 , the percentage of correct classification is: 87.37 % and the loss is 1.139655612079127\n",
      "When the iteration is 32 , the percentage of correct classification is: 87.37 % and the loss is 1.132262227617596\n",
      "When the iteration is 33 , the percentage of correct classification is: 87.42 % and the loss is 1.1252000991663875\n",
      "When the iteration is 34 , the percentage of correct classification is: 87.45 % and the loss is 1.1184459015731985\n",
      "When the iteration is 35 , the percentage of correct classification is: 87.56 % and the loss is 1.1119785470055275\n",
      "When the iteration is 36 , the percentage of correct classification is: 87.64999999999999 % and the loss is 1.1057789294728637\n",
      "When the iteration is 37 , the percentage of correct classification is: 87.68 % and the loss is 1.0998296534231664\n",
      "When the iteration is 38 , the percentage of correct classification is: 87.72999999999999 % and the loss is 1.0941148512417758\n",
      "When the iteration is 39 , the percentage of correct classification is: 87.77000000000001 % and the loss is 1.088620003682387\n",
      "When the iteration is 40 , the percentage of correct classification is: 87.81 % and the loss is 1.0833318007300121\n",
      "When the iteration is 41 , the percentage of correct classification is: 87.87 % and the loss is 1.0782380125640525\n",
      "When the iteration is 42 , the percentage of correct classification is: 87.94 % and the loss is 1.0733273816533013\n",
      "When the iteration is 43 , the percentage of correct classification is: 87.99 % and the loss is 1.0685895254477489\n",
      "When the iteration is 44 , the percentage of correct classification is: 88.06 % and the loss is 1.0640148520586772\n",
      "When the iteration is 45 , the percentage of correct classification is: 88.09 % and the loss is 1.0595944849463859\n",
      "When the iteration is 46 , the percentage of correct classification is: 88.14 % and the loss is 1.0553201965482393\n",
      "When the iteration is 47 , the percentage of correct classification is: 88.21 % and the loss is 1.0511843490562007\n",
      "When the iteration is 48 , the percentage of correct classification is: 88.25 % and the loss is 1.047179841744282\n",
      "When the iteration is 49 , the percentage of correct classification is: 88.28 % and the loss is 1.0433000638544996\n",
      "When the iteration is 50 , the percentage of correct classification is: 88.3 % and the loss is 1.039538852440166\n",
      "When the iteration is 51 , the percentage of correct classification is: 88.33 % and the loss is 1.035890454522776\n",
      "When the iteration is 52 , the percentage of correct classification is: 88.35 % and the loss is 1.0323494930713017\n",
      "When the iteration is 53 , the percentage of correct classification is: 88.39 % and the loss is 1.0289109363468196\n",
      "When the iteration is 54 , the percentage of correct classification is: 88.4 % and the loss is 1.0255700702317863\n",
      "When the iteration is 55 , the percentage of correct classification is: 88.42999999999999 % and the loss is 1.0223224732049563\n",
      "When the iteration is 56 , the percentage of correct classification is: 88.47 % and the loss is 1.0191639936700632\n",
      "When the iteration is 57 , the percentage of correct classification is: 88.5 % and the loss is 1.0160907293812222\n",
      "When the iteration is 58 , the percentage of correct classification is: 88.57000000000001 % and the loss is 1.013099008740622\n",
      "When the iteration is 59 , the percentage of correct classification is: 88.66000000000001 % and the loss is 1.0101853737709636\n",
      "When the iteration is 60 , the percentage of correct classification is: 88.66000000000001 % and the loss is 1.007346564588904\n",
      "When the iteration is 61 , the percentage of correct classification is: 88.68 % and the loss is 1.004579505226121\n",
      "When the iteration is 62 , the percentage of correct classification is: 88.71 % and the loss is 1.0018812906624543\n",
      "When the iteration is 63 , the percentage of correct classification is: 88.75999999999999 % and the loss is 0.9992491749509933\n",
      "When the iteration is 64 , the percentage of correct classification is: 88.8 % and the loss is 0.9966805603285392\n",
      "When the iteration is 65 , the percentage of correct classification is: 88.86 % and the loss is 0.9941729872166253\n",
      "When the iteration is 66 , the percentage of correct classification is: 88.89 % and the loss is 0.991724125028666\n",
      "When the iteration is 67 , the percentage of correct classification is: 88.94 % and the loss is 0.989331763707872\n",
      "When the iteration is 68 , the percentage of correct classification is: 88.97 % and the loss is 0.9869938059285654\n",
      "When the iteration is 69 , the percentage of correct classification is: 88.99000000000001 % and the loss is 0.9847082599005871\n",
      "When the iteration is 70 , the percentage of correct classification is: 89.03 % and the loss is 0.9824732327226908\n",
      "When the iteration is 71 , the percentage of correct classification is: 89.03999999999999 % and the loss is 0.9802869242363641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When the iteration is 72 , the percentage of correct classification is: 89.08 % and the loss is 0.9781476213363467\n",
      "When the iteration is 73 , the percentage of correct classification is: 89.12 % and the loss is 0.9760536926984912\n",
      "When the iteration is 74 , the percentage of correct classification is: 89.12 % and the loss is 0.9740035838894509\n",
      "When the iteration is 75 , the percentage of correct classification is: 89.14 % and the loss is 0.9719958128261008\n",
      "When the iteration is 76 , the percentage of correct classification is: 89.14 % and the loss is 0.9700289655556751\n",
      "When the iteration is 77 , the percentage of correct classification is: 89.17 % and the loss is 0.9681016923303325\n",
      "When the iteration is 78 , the percentage of correct classification is: 89.19 % and the loss is 0.9662127039523043\n",
      "When the iteration is 79 , the percentage of correct classification is: 89.22 % and the loss is 0.964360768367985\n",
      "When the iteration is 80 , the percentage of correct classification is: 89.22 % and the loss is 0.9625447074912733\n",
      "When the iteration is 81 , the percentage of correct classification is: 89.22 % and the loss is 0.9607633942382622\n",
      "When the iteration is 82 , the percentage of correct classification is: 89.24 % and the loss is 0.9590157497569433\n",
      "When the iteration is 83 , the percentage of correct classification is: 89.24 % and the loss is 0.9573007408370425\n",
      "When the iteration is 84 , the percentage of correct classification is: 89.27000000000001 % and the loss is 0.9556173774863813\n",
      "When the iteration is 85 , the percentage of correct classification is: 89.27000000000001 % and the loss is 0.953964710661342\n",
      "When the iteration is 86 , the percentage of correct classification is: 89.29 % and the loss is 0.952341830140041\n",
      "When the iteration is 87 , the percentage of correct classification is: 89.29 % and the loss is 0.9507478625278035\n",
      "When the iteration is 88 , the percentage of correct classification is: 89.32 % and the loss is 0.9491819693853756\n",
      "When the iteration is 89 , the percentage of correct classification is: 89.32 % and the loss is 0.9476433454710977\n",
      "When the iteration is 90 , the percentage of correct classification is: 89.31 % and the loss is 0.9461312170889817\n",
      "When the iteration is 91 , the percentage of correct classification is: 89.33 % and the loss is 0.9446448405352793\n",
      "When the iteration is 92 , the percentage of correct classification is: 89.33 % and the loss is 0.9431835006367186\n",
      "When the iteration is 93 , the percentage of correct classification is: 89.33 % and the loss is 0.9417465093741229\n",
      "When the iteration is 94 , the percentage of correct classification is: 89.33 % and the loss is 0.9403332045856199\n",
      "When the iteration is 95 , the percentage of correct classification is: 89.34 % and the loss is 0.9389429487440838\n",
      "When the iteration is 96 , the percentage of correct classification is: 89.35 % and the loss is 0.9375751278038843\n",
      "When the iteration is 97 , the percentage of correct classification is: 89.36 % and the loss is 0.9362291501123653\n",
      "When the iteration is 98 , the percentage of correct classification is: 89.37 % and the loss is 0.9349044453818356\n",
      "When the iteration is 99 , the percentage of correct classification is: 89.39 % and the loss is 0.9336004637181585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-9.42706457e-06, -1.29160983e-06, -1.10568296e-05, ...,\n",
       "        -4.13120865e-06, -2.44360823e-05, -1.27442326e-05],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       ...,\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(100, X_train, Y_train, X_test, Y_test, 1.e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2a0414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86584347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e79ba2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}